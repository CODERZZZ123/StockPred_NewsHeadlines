{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CODERZZZ123/StockPred_NewsHeadlines/blob/master/pred_stock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9xkIi4fT0sK",
        "outputId": "c84ac509-fb77-404e-8c05-a805dea3edf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk.corpus\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import matplotlib.pyplot as plt\n",
        "# !pip install sklearn\n",
        "import random\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import Normalizer\n",
        "# !pip install textattack\n",
        "# !pip install --upgrade gensim --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hIHZTthYA0tA"
      },
      "outputs": [],
      "source": [
        "# import gensim\n",
        "\n",
        "# !pip install transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aSAHOHjzBHzN"
      },
      "outputs": [],
      "source": [
        "# import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IMYmDEBVBl6R"
      },
      "outputs": [],
      "source": [
        "# !pip install sacremoses --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NsQEyXUxBq2U"
      },
      "outputs": [],
      "source": [
        "# import sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZzENF1KrBvIG"
      },
      "outputs": [],
      "source": [
        "# !pip install nlpaug --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wByHAA0DB0Ch"
      },
      "outputs": [],
      "source": [
        "# import nlpaug.augmenter.char as na\n",
        "# import nlpaug.augmenter.word as naw\n",
        "# import nlpaug.augmenter.sentence as nas\n",
        "# import nlpaug.flow as nafc\n",
        "# from nlpaug.util import Action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "atzWm9jsCLEk"
      },
      "outputs": [],
      "source": [
        "# from nlpaug.util.file.download import DownloadUtil\n",
        "# DownloadUtil.download_word2vec(dest_dir = \".\")\n",
        "# DownloadUtil.download_fasttext(dest_dir = \".\" , model_name = 'crawl-300d-2M')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rN7FEZ0ZuqFO"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# import requests\n",
        "# import time\n",
        "\n",
        "# while True:\n",
        "#     try:\n",
        "#         requests.get('https://www.google.com')\n",
        "#         print(\"Kept alive.\")\n",
        "#     except:\n",
        "#         print(\"Failed to keep alive.\")\n",
        "#     time.sleep(600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RNqcUOuIT0sM"
      },
      "outputs": [],
      "source": [
        "from sklearn import  set_config\n",
        "set_config(display = 'diagram')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1s_eLsA1T0sN"
      },
      "outputs": [],
      "source": [
        "df_NewsDjia = pd.read_csv('News_DJIA.csv', delimiter=',')\n",
        "# df_DjiaStock = pd.read_csv('DJIA_t.csv',delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Im-8hHxS1heY"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Euw0z2hIPiPN"
      },
      "outputs": [],
      "source": [
        "# df_DjiaStock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WIQ6Fn1iT0sN"
      },
      "outputs": [],
      "source": [
        "for i in df_NewsDjia.columns :\n",
        "    df_NewsDjia[i] = df_NewsDjia[i].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "76jhl5TfT0sN"
      },
      "outputs": [],
      "source": [
        "# df_NewsDjia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AdF2Yv7oT0sN"
      },
      "outputs": [],
      "source": [
        "num_columns = df_NewsDjia.columns.shape[0]\n",
        "col_names = df_NewsDjia.columns.values.tolist()\n",
        "col_names = col_names[1:]\n",
        "df_NewsDjia.loc[:, 'merged'] = \" \"\n",
        "for each_col_ind in range(num_columns-1):\n",
        "    df_NewsDjia.loc[:, 'merged'] =  df_NewsDjia.loc[:, 'merged'] + \" \" + df_NewsDjia[col_names[each_col_ind]] + \" \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QpJYzG1RT0sO"
      },
      "outputs": [],
      "source": [
        "df_finalised = df_NewsDjia[['merged']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aTSmdMp5T0sO"
      },
      "outputs": [],
      "source": [
        "date_numric_stopwords = \"THOUSAND MILLION BILLION TRILLION HUNDRED ANNUAL ANNUALLY ANNUM YEAR YEARLY QUARTER QUARTERLY QTR MONTH MONTHLY WEEK WEEKLY DAY DAILY JANUARY FEBRUARY MARCH APRIL MAY JUNE JULY AUGUST SEPTEMBER OCTOBER NOVEMBER DECEMBER JAN FEB MAR APR MAY JUN JUL AUG SEP SEPT OCT NOV DEC MONDAY TUESDAY WEDNESDAY THURSDAY FRIDAY SATURDAY SUNDAY TWO THREE FOUR FIVE SIX SEVEN EIGHT NINE TEN ELEVEN TWELVE THIRTEEN FOURTEEN FIFTEEN SIXTEEN SEVENTEEN EIGHTEEN NINETEEN TWENTY THIRTY FORTY FIFTY SIXTY SEVENTY EIGHTY NINETY FIRST SECOND THIRD FOURTH FIFTH SIXTH SEVENTH EIGHTH NINTH TENTH II III IV V VI VII VIII IX X XI XII XIII XIV XV XVI XVII XVIII XIX XX\"\n",
        "date_numric_stopwords = date_numric_stopwords.lower()\n",
        "date_numric_stopwords = date_numric_stopwords.split(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "m5cRP3mjT0sO"
      },
      "outputs": [],
      "source": [
        "\n",
        "def remove_unecssary_word(sent):\n",
        "    sent = sent.replace(\"b'\",'')\n",
        "    sent = sent.replace('b\"','')\n",
        "    sent = sent.lower()\n",
        "    sent = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", sent)\n",
        "    stop = stopwords.words('english')\n",
        "    stop.extend(date_numric_stopwords)\n",
        "    sent = \" \".join([word for word in sent.split() if word not in (stop)])\n",
        "    sent = \" \".join([WordNetLemmatizer().lemmatize(word) for word in sent.split() ])\n",
        "    return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnZxsRH_T0sO",
        "outputId": "6e436192-72f1-44bb-ffe2-c0c1a71243aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-6847205c14ea>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_finalised['merged'] = df_finalised['merged'].apply(remove_unecssary_word)\n"
          ]
        }
      ],
      "source": [
        "df_finalised['merged'] = df_finalised['merged'].apply(remove_unecssary_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "Wx0BhxO9T0sO",
        "outputId": "9454accb-c65f-421c-96ef-dc1926edfce1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0 georgia down russian warplane country move brink war breaking musharraf impeached russia today column troop roll south ossetia footage fighting youtube russian tank moving towards capital south ossetia reportedly completely destroyed georgian artillery fire afghan child raped impunity un official say sick old raped nothing 150 russian tank entered south ossetia whilst georgia shoot russian jet breaking georgia invades south ossetia russia warned would intervene so side enemy combatent trial nothing sham salim haman sentenced 5 12 year kept longer anyway feel like georgian troop retreat osettain capital presumably leaving several people killed video u prep georgia war russia rice give green light israel attack iran say u veto israeli military ops announcingclass action lawsuit behalf american public fbi sorussia georgia war nyts top story opening ceremony olympics fucking disgrace yet proof decline journalism china tell bush stay country affair world war start today georgia invades south ossetia russia get involved nato absorb georgia unleash full scale war alqaeda face islamist backlash condoleezza rice u would act prevent israeli strike iran israeli defense minister ehud barak israel prepared uncompromising victory case military hostility busy european union approved new sanction iran protest nuclear programme georgia withdraw 1000 soldier iraq help fight russian force georgia breakaway region south ossetia pentagon think attacking iran bad idea u news amp world report caucasus crisis georgia invades south ossetia indian shoe manufactory series like work visitor suffering mental illness banned olympics help mexico kidnapping surge'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "df_finalised.iloc[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "A5SR3rl8Uw2y"
      },
      "outputs": [],
      "source": [
        "# from textattack.augmentation import EmbeddingAugmenter\n",
        "# embed_aug = EmbeddingAugmenter()\n",
        "# embed_aug.augment(df_finalised.iloc[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7SSR3l6UEIGr"
      },
      "outputs": [],
      "source": [
        "# from textattack.augmentation import WordNetAugmenter\n",
        "# wordnet_aug = WordNetAugmenter()\n",
        "# wordnet_aug.augment(df_finalised.iloc[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "K7x4r45pE-6C"
      },
      "outputs": [],
      "source": [
        "# from textattack.augmentation import EasyDataAugmenter\n",
        "# eda_aug = EasyDataAugmenter()\n",
        "# eda_aug.augment(df_finalised.iloc[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Wv9DIdYsT0sP"
      },
      "outputs": [],
      "source": [
        "df_finalised = pd.concat([df_finalised,df_NewsDjia['Label']],axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "M42KsKBjT0sP"
      },
      "outputs": [],
      "source": [
        "# Positive_word = \"\"\n",
        "# with open('Positive_words.txt', 'r') as file:\n",
        "#     Positive_word = file.read().replace('\\n', '')\n",
        "# Positive_word = \" \".join([WordNetLemmatizer().lemmatize(word) for word in Positive_word.split(',') ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "oi832ifcT0sP"
      },
      "outputs": [],
      "source": [
        "# Negative_word = \"\"\n",
        "# with open('Negative_words.txt','r') as file:\n",
        "#     Negative_word = file.read().replace('\\n','')\n",
        "# Negative_word = \" \".join([WordNetLemmatizer().lemmatize(word) for word in Negative_word.split(',') ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cen4cv_yT0sP"
      },
      "outputs": [],
      "source": [
        "# Positive_word = Positive_word.split(',')\n",
        "# Negative_word = Negative_word.split(',')\n",
        "# Negative_word = Negative_word[0].split()\n",
        "# Positive_word = Positive_word[0].split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "vQkp4GoWT0sP"
      },
      "outputs": [],
      "source": [
        "# set_post = set(Positive_word)\n",
        "# set_neg = set(Negative_word)\n",
        "# def Count(obj):\n",
        "#     count_post = 1\n",
        "#     count_neg = 1\n",
        "#     obj = obj.split()\n",
        "#     for i in obj:\n",
        "#         if i in set_post:\n",
        "#             count_post = count_post + 1\n",
        "#         elif i in set_neg:\n",
        "#             count_neg = count_neg + 1\n",
        "#     return count_post/count_neg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dOZFtn3KT0sP"
      },
      "outputs": [],
      "source": [
        "# df_finalised['ratio_pos_neg'] = df_finalised['merged'].apply(Count)\n",
        "# ratio_column = df_finalised['ratio_pos_neg']\n",
        "# ratio_column = np.array(ratio_column).reshape((-1,1))\n",
        "X_data = df_finalised['merged']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9NYhdmewZQ5w"
      },
      "outputs": [],
      "source": [
        "Y_data = df_finalised['Label']\n",
        "Y_data = Y_data.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "ASqt7TciSdK6",
        "outputId": "28e38401-d1ea-40a0-f9d6-2cc1c86776b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0 georgia down russian warplane country move brink war breaking musharraf impeached russia today column troop roll south ossetia footage fighting youtube russian tank moving towards capital south ossetia reportedly completely destroyed georgian artillery fire afghan child raped impunity un official say sick old raped nothing 150 russian tank entered south ossetia whilst georgia shoot russian jet breaking georgia invades south ossetia russia warned would intervene so side enemy combatent trial nothing sham salim haman sentenced 5 12 year kept longer anyway feel like georgian troop retreat osettain capital presumably leaving several people killed video u prep georgia war russia rice give green light israel attack iran say u veto israeli military ops announcingclass action lawsuit behalf american public fbi sorussia georgia war nyts top story opening ceremony olympics fucking disgrace yet proof decline journalism china tell bush stay country affair world war start today georgia invades south ossetia russia get involved nato absorb georgia unleash full scale war alqaeda face islamist backlash condoleezza rice u would act prevent israeli strike iran israeli defense minister ehud barak israel prepared uncompromising victory case military hostility busy european union approved new sanction iran protest nuclear programme georgia withdraw 1000 soldier iraq help fight russian force georgia breakaway region south ossetia pentagon think attacking iran bad idea u news amp world report caucasus crisis georgia invades south ossetia indian shoe manufactory series like work visitor suffering mental illness banned olympics help mexico kidnapping surge'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "X_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "AWJM39iIGonj"
      },
      "outputs": [],
      "source": [
        "# from textattack.augmentation import EasyDataAugmenter\n",
        "# eda_aug = EasyDataAugmenter()\n",
        "# data_X = []\n",
        "# label = []\n",
        "# # open('/content/drive/MyDrive/Colab Notebooks/Pred_stock_newheadline/data.txt', 'w').close()\n",
        "# # open('/content/drive/MyDrive/Colab Notebooks/Pred_stock_newheadline/label.txt','w').close()\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/Pred_stock_newheadline/data.txt', 'a') as f1 , open('/content/drive/MyDrive/Colab Notebooks/Pred_stock_newheadline/label.txt','a') as f2:\n",
        "#   for i in range(0,X_data.shape[0]):\n",
        "#     data_X.append(X_data[i])\n",
        "#     label.append(Y_data[i])\n",
        "#     f1.write(X_data[i])\n",
        "#     f1.write(\",\")\n",
        "#     y = str(Y_data[i])\n",
        "#     f2.write(y)\n",
        "#     f2.write(\",\")\n",
        "#     if i%10 == 0:\n",
        "#       data = eda_aug.augment(X_data[i])\n",
        "#       for d in data:\n",
        "#         data_X.append(d)\n",
        "#         label.append(Y_data[i])\n",
        "#         f1.write(d)\n",
        "#         f1.write(\",\")\n",
        "#         f2.write(y)\n",
        "#         f2.write(\",\")\n",
        "\n",
        "#     print(i)\n",
        "# open('/content/drive/MyDrive/Colab Notebooks/Pred_stock_newheadline/train_data.txt', 'w').close()\n",
        "\n",
        "# Note test sample isbeing already saved aside so no need to run it again\n",
        "# open('/content/drive/MyDrive/Colab Notebooks/Pred_stock_newheadline/test_data.txt','w').close()\n",
        "\n",
        "# for i in range(0,X_data.shape[0]//10+1):\n",
        "#   if i >= X_data.shape[0]:\n",
        "#     break\n",
        "\n",
        "#   random_numbers = random.sample(range(0, 10), 5)\n",
        "#   for k,l in enumerate(random_numbers): random_numbers[k] += i*10\n",
        "#   random_numbers.sort()\n",
        "#   # print(random_numbers)\n",
        "#   for j in range(0,10):\n",
        "#     if j + i*10 >= X_data.shape[0] :\n",
        "#       break\n",
        "#     if j + i*10 in random_numbers:\n",
        "#       with open('/content/drive/MyDrive/Colab Notebooks/Pred_stock_newheadline/train_data.txt', 'a') as f1 :\n",
        "        # code for te text augementation on the jth index\n",
        "        # f1.write(\"\")\n",
        "        # t = 0\n",
        "\n",
        "    # else:\n",
        "    #   with open('/content/drive/MyDrive/Colab Notebooks/Pred_stock_newheadline/test_data.txt', 'a') as f2:\n",
        "    #     # code for the text augmentation on the jth index\n",
        "    #     f2.write(X_data[j + i*10])\n",
        "    #     f2.write(\",\")\n",
        "    # print(j + i*10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm29KgKnZULw",
        "outputId": "aa9988cb-c691-4d0d-ccd4-e14b420e2ed5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "Y_data = np.array(Y_data)\n",
        "Y_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Ji_NATWSH5Lc"
      },
      "outputs": [],
      "source": [
        "# X_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "drGIIgbRy3un"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9EUKXPVmWLIL"
      },
      "outputs": [],
      "source": [
        "# data_X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "kETBXbGpT0sP"
      },
      "outputs": [],
      "source": [
        "data_augmented = np.genfromtxt('/content/drive/MyDrive/Colab Notebooks/Pred_stock_newheadline/data.txt',dtype = str , delimiter=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSSZigVrT0sP",
        "outputId": "aea51c51-63be-4f15-c11e-8c51a774f168"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2864,)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "data_augmented.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArtMidVuNwaZ",
        "outputId": "bcec79a2-66ae-4855-f83e-fad600c8fb6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2788\n",
            "2864\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "count2 = 0\n",
        "for i in data_augmented:\n",
        "    if len(i) != 0:\n",
        "        if i[0] =='0' or i[0] == '1':\n",
        "            if i[1] == \" \":\n",
        "\n",
        "              count = count + 1\n",
        "    count2 = count2 + 1\n",
        "print(count)\n",
        "print(count2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "7pQPHfpfN20C"
      },
      "outputs": [],
      "source": [
        "index = 0\n",
        "for i in data_augmented:\n",
        "  if len(i) != 0 :\n",
        "    if i[0] != '1' and i[0] != '0' :\n",
        "        data_augmented[index] = data_augmented[index-1][0] + \" \" + i\n",
        "    index += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRtyCRn3CFL8",
        "outputId": "16377e7d-7524-4d95-f36d-eaca139570e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2864,)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "data_augmented.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tbYTHZwQDVP",
        "outputId": "c34ad4c3-e028-472b-b58d-e9932e9f9a39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2864,)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "data_augmented.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "XF9KVQNz2dOp"
      },
      "outputs": [],
      "source": [
        "data_augmented = data_augmented[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "-VT5orgXRvTr"
      },
      "outputs": [],
      "source": [
        "label_updated = data_augmented.astype('<U1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4sSo8s9TLGl",
        "outputId": "8cda905a-3e58-4700-d23f-b360002885cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '0', '0', ..., '1', '1', '0'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "label_updated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f36xhhHWXVNa",
        "outputId": "83ef3cb4-0a12-4da6-902d-af5ba3ec159f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-39bc489429a0>:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  label_updated = label_updated.astype(np.float)\n"
          ]
        }
      ],
      "source": [
        "label_updated = label_updated.astype(np.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "FHkqIvD9S0wu"
      },
      "outputs": [],
      "source": [
        "data_augmented = list(data_augmented)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "M4rxs4nJSZFx"
      },
      "outputs": [],
      "source": [
        "data_augmented = [i[2:] for i in data_augmented]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "9WIy5x2oSgTy"
      },
      "outputs": [],
      "source": [
        "# data_augmented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxVp8lhxT0sP",
        "outputId": "927c6c05-7180-47cb-ffaf-d1de0ce9d368"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1989,)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "X_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "meXgTNQtT0sQ"
      },
      "outputs": [],
      "source": [
        "# x_train , x_test , y_train, y_test = train_test_split(data_augmented,label_updated , test_size = 0.2 , random_state = 10)\n",
        "x_train , x_test , y_train , y_test = data_augmented[:2290] , data_augmented[2290:] , label_updated[:2290] , label_updated[2290:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "S2rkrR9OT0sQ"
      },
      "outputs": [],
      "source": [
        "tf_idf = TfidfVectorizer(min_df=10  )\n",
        "x_train_tf = tf_idf.fit_transform(x_train)\n",
        "x_test_tf = tf_idf.transform(x_test)\n",
        "x_train = x_train_tf.toarray()\n",
        "x_test = x_test_tf.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "cpJ8wLIdT0sQ"
      },
      "outputs": [],
      "source": [
        "# mean_not_zero = x_train[x_train != 0].mean()\n",
        "# x_train[x_train == 0 ] = x_train[x_train == 0] +  mean_not_zero\n",
        "# x_test[x_test == 0 ] = x_test[x_test == 0] + mean_not_zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "nMAN-8NhT0sQ"
      },
      "outputs": [],
      "source": [
        "# ct_vect = CountVectorizer(ngram_range=(1,2) , min_df = 5)\n",
        "# x_train = ct_vect.fit_transform(x_train).toarray()\n",
        "# x_test = ct_vect.transform(x_test).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "WITB1UvPLDbG"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "CNrl6WtzT0sQ"
      },
      "outputs": [],
      "source": [
        "# scaler = StandardScaler()\n",
        "# scaler.fit(x_train)\n",
        "# x_train = scaler.transform(x_train)\n",
        "# x_test = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "9VWjlHJyT0sQ"
      },
      "outputs": [],
      "source": [
        "# pca = PCA()\n",
        "# pca.fit(x_train)\n",
        "# cumsum = np.cumsum(pca.explained_variance_ratio_)*100\n",
        "# d = [n for n in range(len(cumsum))]\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# plt.plot(d,cumsum, color = 'red',label='cumulative explained variance')\n",
        "# plt.title('Cumulative Explained Variance as a Function of the Number of Components')\n",
        "# plt.ylabel('Cumulative Explained variance')\n",
        "# plt.xlabel('Principal components')\n",
        "# plt.axhline(y = 90, color='k', linestyle='--', label = '95% Explained Variance')\n",
        "# plt.legend(loc='best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Vkt-lDv5T0sQ"
      },
      "outputs": [],
      "source": [
        "# # VARIANCE EXPLAINED 90%\n",
        "# pca = PCA(0.90)\n",
        "# pca.fit(x_train)\n",
        "# x_train = pca.transform(x_train)\n",
        "# x_test = pca.transform(x_test)\n",
        "# pca.explained_variance_ratio_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "0bwJUnIIT0sQ"
      },
      "outputs": [],
      "source": [
        "# K = [int(i) for i in range(x_train.shape[0]//3)]\n",
        "# param_grid = {\n",
        "#     'n_neighbors' : K\n",
        "# }\n",
        "# knn = KNeighborsClassifier()\n",
        "# grid_search = GridSearchCV(estimator=knn,scoring='accuracy',param_grid=param_grid,cv = 10,n_jobs = -1,verbose = 2)\n",
        "# grid_search.fit(x_train,y_train)\n",
        "# grid_search.best_estimator_\n",
        "# knn = KNeighborsClassifier(n_neighbors=1)\n",
        "# knn.fit(x_train,y_train)\n",
        "# y_pred = knn.predict(x_test)\n",
        "# print(accuracy_score(y_pred,y_test))\n",
        "# print(classification_report(y_pred,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "qIVzORqM4cJi"
      },
      "outputs": [],
      "source": [
        "# scaler = StandardScaler()\n",
        "# scaler.fit(x_train)\n",
        "# x_train_for_distance_based = scaler.transform(x_train)\n",
        "# x_test_for_distance_based = scaler.transform(x_test)\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# penalty = ['l1','l2']\n",
        "# # max_iter= [1000]\n",
        "# C= [ 0.01,0.05 , 0.07 , 0.3,0.1,0.5,1,5,10,20,30,40,70,100]\n",
        "# solver = ['lbfgs']\n",
        "# param_grid = {\n",
        "#     'penalty' : penalty,\n",
        "#     # 'max_iter' : max_iter,\n",
        "#     'solver' : solver,\n",
        "#     'C' : C\n",
        "# }\n",
        "# LoRG = LogisticRegression(max_iter = 1000)\n",
        "# random_search = RandomizedSearchCV(estimator = LoRG  , n_iter=100 , scoring = 'accuracy', param_distributions = param_grid , cv  = 5  , n_jobs = -1, verbose = 2  )\n",
        "# random_search.fit(x_train_for_distance_based,y_train)\n",
        "# best_param_LoRG = random_search.best_estimator_\n",
        "# # best_param_LoRG\n",
        "# print(accuracy_score(y_test  , best_param_LoRG.predict(x_test_for_distance_based)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "maWXAYGkJb4s"
      },
      "outputs": [],
      "source": [
        "# log_m1 = LogisticRegression(penalty = 'l2' , solver = 'lbfgs'  , max_iter = 5000  , intercept_scaling=10)\n",
        "# log_m2 = LogisticRegression(penalty = 'l2' , solver = 'liblinear'  , max_iter = 5000  , intercept_scaling=10)\n",
        "# log_m3 = LogisticRegression(penalty = 'l2' , solver = 'newton-cg'  , max_iter = 5000  , intercept_scaling = 10)\n",
        "# log_m4 = LogisticRegression(penalty = 'l2' , solver = 'newton-cholesky'  , max_iter = 5000 , intercept_scaling = 10 )\n",
        "# log_m5 = LogisticRegression(penalty = 'l1' , solver = 'liblinear'  , max_iter = 5000  , intercept_scaling = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "-yfWF56dz4rf"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# log_m1 = LogisticRegression(penalty = 'l2' , solver = 'lbfgs'  , max_iter = 1000 )\n",
        "# log_m1 = LogisticRegression(penalty = 'l2' , solver = 'lbfgs'  , max_iter = 1000 )\n",
        "# estimators = [('log_m1' , log_m1) , ('log_m2' , log_m2) , ('log_m3' , log_m3) , ('log_m4' , log_m4) , ('log_m5', log_m5)]\n",
        "# VCL = VotingClassifier(estimators = estimators)\n",
        "# voting = ['hard' , 'soft']\n",
        "# param_grid  = {\n",
        "#     'voting' : voting\n",
        "# }\n",
        "# grid_search = GridSearchCV(estimator = VCL , scoring = 'accuracy' , param_grid = param_grid , cv = 5 , n_jobs = -1 , verbose = 2)\n",
        "# grid_search.fit(x_train,y_train)\n",
        "# best_param_VCl = grid_search.best_estimator_\n",
        "# print(accuracy_score( best_param_VCl.predict(x_test), y_test ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "uRhuX-DN5vJi"
      },
      "outputs": [],
      "source": [
        "# log_m1.fit(x_train,y_train)\n",
        "# log_m2.fit(x_train,y_train)\n",
        "# log_m3.fit(x_train,y_train)\n",
        "# log_m4.fit(x_train,y_train)\n",
        "# log_m5.fit(x_train,y_train)\n",
        "# print(accuracy_score(y_test,log_m1.predict(x_test)))\n",
        "# print(accuracy_score(y_test,log_m2.predict(x_test)))\n",
        "# print(accuracy_score(y_test,log_m3.predict(x_test)))\n",
        "# print(accuracy_score(y_test,log_m4.predict(x_test)))\n",
        "# print(accuracy_score(y_test,log_m5.predict(x_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "ySuamYBCr4Yp"
      },
      "outputs": [],
      "source": [
        "scaler = Normalizer()\n",
        "scaler.fit(x_train)\n",
        "x_train_for_distance_based = scaler.transform(x_train)\n",
        "x_test_for_distance_based = scaler.transform(x_test)\n",
        "\n",
        "# Distance based algorithm requrire scaling so we need to do that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "xteNW1JsHvLx"
      },
      "outputs": [],
      "source": [
        "# SGD\n",
        "\n",
        "# loss = ['hinge', 'log_loss'  , 'perceptron']\n",
        "# alpha = [0.000001, 0.00001 , 0.0001 , 0.001]\n",
        "# max_iter = [1000 , 2000]\n",
        "# tol = [0.0001 , 0.001 , 0.01 , 0.1]\n",
        "# eta0= [0.001, 0.01,0.1]\n",
        "# learning_rate = ['optimal' , 'adaptive']\n",
        "# param_grid = {\n",
        "#       'loss' : loss ,\n",
        "#       'alpha' : alpha,\n",
        "#       'max_iter' :max_iter,\n",
        "#       'tol' : tol,\n",
        "#       'learning_rate' : learning_rate,\n",
        "#       'eta0' : eta0\n",
        "# }\n",
        "# sgd = SGDClassifier(early_stopping=True)\n",
        "# random_search = RandomizedSearchCV(estimator = sgd ,n_iter=100 , scoring = 'accuracy', param_distributions = param_grid , cv  = 4  , n_jobs = -1, verbose = 2 , error_score='raise' )\n",
        "# random_search.fit(x_train_for_distance_based,y_train)\n",
        "# best_estimator_sgd = random_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "kS-rOL0bNhrn"
      },
      "outputs": [],
      "source": [
        "# print(accuracy_score(best_estimator_sgd.predict(x_test_for_distance_based) , y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "yQ5RuxqqOS-I"
      },
      "outputs": [],
      "source": [
        "# best_estimator_sgd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "Y-TRu5YYNwhx"
      },
      "outputs": [],
      "source": [
        "# random_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "wUIZ0W7BOxxN"
      },
      "outputs": [],
      "source": [
        "# # Gridserach cv for the SGD\n",
        "# alpha = [0.0000001,0.0000005,.000001 ,00.00005 , 0.0001]\n",
        "# tol = [0.00001, 0.00005 , 0.0001 , 0.0003 ,0.0005]\n",
        "# max_iter = [1000 ,1500 , 2000]\n",
        "# eta0 = [0.01,0.05,0.1 , 0.5 ,1]\n",
        "# learning_rate = ['optimal' , 'adaptive']\n",
        "# param_grid = {\n",
        "#     'alpha' : alpha,\n",
        "#     'tol' : tol,\n",
        "#     'max_iter': max_iter,\n",
        "#     'eta0' : eta0,\n",
        "#     'learning_rate' : learning_rate\n",
        "# }\n",
        "# sgd = SGDClassifier(early_stopping=True)\n",
        "# grid_search = GridSearchCV(estimator = sgd , scoring = 'accuracy' , param_grid = param_grid , n_jobs = -1 , cv = 4,verbose = 2 , error_score = 'raise' )\n",
        "# grid_search.fit(x_train_for_distance_based,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "0JzkOIAhVxkW"
      },
      "outputs": [],
      "source": [
        "# sgd_grid_best_params = grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "voANfkPbjDGX"
      },
      "outputs": [],
      "source": [
        "# sgd_grid_best_estimator = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "_MDPDMvQjgF1"
      },
      "outputs": [],
      "source": [
        "# sgd_grid_best_params"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD best params\n",
        "# {'alpha': 1e-07,\n",
        "#  'eta0': 0.1,\n",
        "#  'learning_rate': 'optimal',\n",
        "#  'max_iter': 1000,\n",
        "#  'tol': 0.0001}"
      ],
      "metadata": {
        "id": "i__wc0fhfuTn"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "YkZGUPmjjFkH"
      },
      "outputs": [],
      "source": [
        "# print(accuracy_score(y_test,sgd_grid_best_estimator.predict(x_test_for_distance_based)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = SGDClassifier(alpha = 0.0000001 , eta0 = 0.1 , learning_rate = 'optimal' , max_iter = 1000 , tol = 0.0001)\n",
        "sgd.fit(x_train_for_distance_based,y_train)\n",
        "print(accuracy_score(sgd.predict( x_test_for_distance_based),y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFQ6vZKFIvNi",
        "outputId": "d9c7dba2-9fd4-463e-b1c6-539e1dc0e0b0"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5951134380453752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDLSD9qt__kW",
        "outputId": "175cc906-1ef1-4c21-c26f-21f70288485e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6020942408376964"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "# Naive bayes\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(x_train_for_distance_based,y_train)\n",
        "# gnb.partial_fit(x_train,y_train,[0,1])\n",
        "gnb.score(x_test_for_distance_based,y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZJVW6s2COZa",
        "outputId": "39a67dd8-8328-4829-b9ed-175c56834799"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5951134380453752"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "mun = MultinomialNB(alpha = 1 , force_alpha='warn')\n",
        "mun.fit(x_train_for_distance_based,y_train)\n",
        "mun.score(x_test_for_distance_based, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZYPrqPoQt-a",
        "outputId": "a83c8af4-8467-4447-e1ca-c494407d9b21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6020942408376964"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "from sklearn.naive_bayes import ComplementNB\n",
        "cmb = ComplementNB(alpha = 1 , force_alpha = 'warn')\n",
        "cmb.fit(x_train_for_distance_based,y_train)\n",
        "cmb.score(x_test_for_distance_based,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "Ju-ymMMu3SoC"
      },
      "outputs": [],
      "source": [
        "# from sklearn.ensemble import VotingClassifier\n",
        "# estimators  = [('gaussain',gnb),('Multinomial',mun),('Complement',cmb)]\n",
        "# VCL = VotingClassifier(estimators = estimators)\n",
        "# voting = ['hard','soft']\n",
        "# param_grid  = {\n",
        "#     'voting' : voting\n",
        "# }\n",
        "# grid_search = GridSearchCV(estimator = VCL , scoring = 'accuracy' , param_grid = param_grid , cv = 5 , n_jobs = -1 , verbose = 2)\n",
        "# grid_search.fit(x_train,y_train)\n",
        "# best_param_VCl = grid_search.best_estimator_\n",
        "# print(accuracy_score( best_param_VCl.predict(x_test), y_test ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "7auBNFUV7YOb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "mXR8cyIT_-0K"
      },
      "outputs": [],
      "source": [
        "# xcgvxcv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Y9krJ4mwT0sQ"
      },
      "outputs": [],
      "source": [
        "# C = [0.05 , 0.1 , 0.5  , 1 , 5 , 10 ,15 , 25]\n",
        "# kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "# gamma = ['scale','auto']\n",
        "# degree = [int(x) for x in range(1,2)]\n",
        "# param_grid = {\n",
        "#     'kernel' : kernel,\n",
        "#     'gamma' : gamma,\n",
        "#     'degree' : degree,\n",
        "#     'C' : C\n",
        "# }\n",
        "# svc = SVC()\n",
        "# grid_search = GridSearchCV(estimator=svc,scoring='accuracy',param_grid=param_grid,cv = 3,n_jobs = -1,verbose = 6)\n",
        "# grid_search.fit(x_train,y_train)\n",
        "# best_gird_search = grid_search.best_estimator_\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# y_pred = best_gird_search.predict(x_test)\n",
        "# print(confusion_matrix(y_test,y_pred))\n",
        "# print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred)))\n",
        "# print(accuracy_score(y_train,best_gird_search.predict(x_train)))\n",
        "# Score = cross_val_score(best_gird_search,X_data,Y_data,cv = 5)\n",
        "# Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "o66bh0haFdSJ"
      },
      "outputs": [],
      "source": [
        "# grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "GbhpT4dET0sR"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import accuracy_score\n",
        "# model = grid_search.best_params_\n",
        "# model.fit(x_train,y_train)\n",
        "# y_pred = model.predict(x_test)\n",
        "# print(confusion_matrix(y_test,y_pred))\n",
        "# print(\"Accuracy for the trained data is {}\".format(accuracy_score(y_train,model.predict(x_train))))\n",
        "# print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred)))\n",
        "# print(\"classification report {}\".format(classification_report(y_test,y_pred)))\n",
        "# Score = cross_val_score(model,X_data,Y_data,cv = 5)\n",
        "# Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "JasQiE2XXIZX"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "373C8LooT0sR"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense\n",
        "# model = Sequential()\n",
        "# model.add(Dense(12,input_shape = (x_train.shape[1],),activation = 'relu'))\n",
        "# model.add(Dense(8,activation = 'relu'))\n",
        "# model.add(Dense(1,activation = 'sigmoid'))\n",
        "# model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "# model.fit(x_train,y_train,epochs=200,batch_size=1000)\n",
        "# predictions = (model.predict(x_test) > 0.5).astype(int)\n",
        "# abs(predictions.T - y_test).sum()/y_test.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "nWFCEGKzT0sR"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# score_test = []\n",
        "# score_train = []\n",
        "# scale = [i for i in range(1,200,5)]\n",
        "# for i in range(1 , 200 , 5):\n",
        "#   randomclassifier=RandomForestClassifier(n_estimators=i,criterion='entropy')\n",
        "#   randomclassifier.fit(x_train,y_train)\n",
        "#   predictions = randomclassifier.predict(x_test)\n",
        "#   predictions_train = randomclassifier.predict(x_train)\n",
        "#   score_test.append(accuracy_score(y_test,predictions))\n",
        "#   score_train.append(accuracy_score(y_train,predictions_train))\n",
        "# plt.plot(scale ,score_test )\n",
        "# plt.plot(scale ,score_train )\n",
        "\n",
        "  # matrix=confusion_matrix(y_test,predictions)\n",
        "# print(matrix)\n",
        "# score=\n",
        "# print(score)\n",
        "# report=classification_report(y_test,predictions)\n",
        "# print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "i-KYnuZGmptq"
      },
      "outputs": [],
      "source": [
        "# criterion = ['gini' , 'entropy']\n",
        "# max_depth = [5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37]\n",
        "# min_samples_split = [ 3 , 5 , 10, 20 , 30]\n",
        "# min_samples_leaf = [30,20,10,5]\n",
        "# max_features = ['sqrt','log2']\n",
        "# param_grid = {\n",
        "#     'criterion' : criterion,\n",
        "#     'max_depth' : max_depth,\n",
        "#     'max_features' : max_features\n",
        "# }\n",
        "# dtc = DecisionTreeClassifier()\n",
        "# grid_search = GridSearchCV(estimator = dtc , scoring = 'accuracy' , param_grid = param_grid , cv = 5 , n_jobs = -1 , verbose = 2 , error_score = 'raise')\n",
        "# grid_search.fit(x_train_for_distance_based,y_train)\n",
        "# best_estimator_dt = grid_search.best_estimator_\n",
        "# best_params_dt = grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "BRH0q9nApma8"
      },
      "outputs": [],
      "source": [
        "# print(accuracy_score(y_test,best_estimator_dt.predict(x_test_for_distance_based)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# best_estimator_dt"
      ],
      "metadata": {
        "id": "4Pkl0Np0KgcH"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier(max_depth = 31 , criterion = 'entropy' , max_features = 'sqrt' )\n",
        "dt.fit(x_train_for_distance_based ,y_train)\n",
        "print(accuracy_score(dt.predict(x_test_for_distance_based),y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAGx20hDahiE",
        "outputId": "3b0d7b63-4a22-4781-cb7b-b97bf28f8de1"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5724258289703316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "8ow7bdcxVtPQ"
      },
      "outputs": [],
      "source": [
        "# K = [3 , 5   ,7 ,11 ,13 ,15  ,19, 23 ,25,29 ,33 ,35  ]\n",
        "# param_grid = {\n",
        "#     'n_neighbors' : K\n",
        "# }\n",
        "# knn = KNeighborsClassifier()\n",
        "# grid_search = GridSearchCV(estimator=knn,scoring='accuracy',param_grid=param_grid,cv = 10,n_jobs = -1,verbose = 2)\n",
        "# grid_search.fit(x_train_for_distance_based,y_train)\n",
        "# knn_best_estimator = grid_search.best_estimator_\n",
        "# print(accuracy_score(knn_best_estimator.predict(x_test_for_distance_based),y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = 19)\n",
        "knn.fit(x_train_for_distance_based,y_train)\n",
        "print(accuracy_score(y_test,knn.predict(x_test_for_distance_based)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRV9kv09aQYM",
        "outputId": "49536bd8-2b4e-4754-a764-770ef29bb848"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.525305410122164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owpYig4Zd-gY",
        "outputId": "bcb2bb98-41f6-4f8e-9dd5-385a3ec12474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.49344978        nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5881326352530541\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "estimators  = [('gaussain',gnb),('Stochastic_gradient_descent',sgd) ,('dciesion_tree',dt) , ('Kneighbors',knn)]\n",
        "VCL = VotingClassifier(estimators = estimators)\n",
        "voting = ['hard','soft']\n",
        "param_grid  = {\n",
        "    'voting' : voting\n",
        "}\n",
        "grid_search = GridSearchCV(estimator = VCL , scoring = 'accuracy' , param_grid = param_grid , cv = 5 , n_jobs = -1 , verbose = 2)\n",
        "grid_search.fit(x_train_for_distance_based,y_train)\n",
        "best_param_VCl_finalised = grid_search.best_estimator_\n",
        "print(accuracy_score( best_param_VCl_finalised.predict(x_test_for_distance_based), y_test ))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hxkvtTeCcwKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  , ('multinomil_naive_bayes',mun) ,('Complement_naive_bayes',cmb)"
      ],
      "metadata": {
        "id": "tgEVLD-49hDf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}